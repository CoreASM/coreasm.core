/*	
 * ParserTools.java 	$Revision: 80 $
 * 
 * Copyright (C) 2007 Roozbeh Farahbod
 *
 * Last modified by $Author: rfarahbod $ on $Date: 2009-07-24 16:25:41 +0200 (Fr, 24 Jul 2009) $.
 *
 * Licensed under the Academic Free License version 3.0
 *   http://www.opensource.org/licenses/afl-3.0.php
 *   http://www.coreasm.org/afl-3.0.php
 *
 */
 
package org.coreasm.engine.parser;

import java.lang.reflect.Array;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Set;
import java.util.regex.Matcher;

import org.coreasm.engine.EngineError;
import org.coreasm.engine.interpreter.ASTNode;
import org.coreasm.engine.interpreter.Node;
import org.coreasm.engine.interpreter.ScannerInfo;
import org.coreasm.tools.Logger;

import jfun.parsec.FromToken;
import jfun.parsec.Lexers;
import jfun.parsec.Map;
import jfun.parsec.ObjectPredicate;
import jfun.parsec.Parser;
import jfun.parsec.ParserEval;
import jfun.parsec.Parsers;
import jfun.parsec.Scanners;
import jfun.parsec.Terms;
import jfun.parsec.Tok;
import jfun.parsec.Tokenizer;
import jfun.parsec.Words;
import jfun.parsec._;
import jfun.parsec.pattern.Pattern;
import jfun.parsec.pattern.Patterns;
import jfun.parsec.tokens.TokenWord;
import jfun.parsec.tokens.TypedToken;

/** 
 * This class provides some auxiliary services for parsing. 
 *   
 * @author Roozbeh Farahbod
 * @version 1.0, $Revision: 80 $, Last modified: $Date: 2009-07-24 16:25:41 +0200 (Fr, 24 Jul 2009) $
 */
public class ParserTools {
	
	/* keeps track of ParserTools instances */
	private static java.util.Map<Thread, ParserTools> instances = null;
	
	
	/* identifier parser singleton */
	private Parser<Node> identifierParser = null;
	
	/* string tokenizer singleton */
	private StringTokenizer stringTokenizer = null;
	
	/* whitespace parser singleton */ 
	private Parser<Node> whitespaceParser = null;
	
	/* delimiter parser singleton */ 
	private Parser<Node> delimiterParser = null;
	
	/* optional delimiter parser singleton */ 
	private Parser<Node> optionalDelimiterParser = null;
	
	/* delimiter with eol parser singleton */
	private Parser<Node> eolDelimParser = null;

	/* delimiter without eol parser singleton */
	private Parser<Node> nonEOLDelimParser = null;

	/* space/tab delimiter parser singleton */
	private Parser<Node> spaceTabDelimParser = null;

	/* a pattern that rejects the sequence if it is a keyword */
	private Pattern identifierPattern = null;
	
	/* all the operator parsers created so far in this runtime */
	private java.util.Map<String, Parser<Node>> oprParsers = null;
	
	/* all the keyword parsers created so far in this runtime */
	private java.util.Map<String, Parser<Node>> kwParsers = null;

	/* list of operators provided by plug-ins */
	private String[] operators = null;
	private Set<String> operatorSet = null;
	
	/* list of keywords provided by plug-ins */
	private String[] keywords = null;
	private Set<String> keywordSet = null;
	
	/* the Terms object for lexing and parsing operators and keywords */
	private Terms words = null;
	
	/* the lexer for operators and keywords and identifiers */
	private Parser<Tok> lexer = null;
	
	/*
	 * Private constructor to avoid default constructor.
	 */
	private ParserTools() {}
	
	/**
	 * Create a new ParserTools singleton for the current thread.
	 *  
	 * @return an instance of ParserTools
	 */
	public static synchronized ParserTools getInstance() {
		if (instances == null) 
			instances = new HashMap<Thread, ParserTools>();
		
		ParserTools instance = instances.get(Thread.currentThread());
		
		if (instances.get(Thread.currentThread()) == null) {
			instance = new ParserTools();
			instances.put(Thread.currentThread(), instance);
		}
		
		return instance;
	}
	
	public void initialize(String[] operators, String[] keywords) {
		if (words == null) {
			
			// caching values for future use
			this.operators = operators;
			operatorSet = new HashSet<String>();
			for (String opr: operators)
				operatorSet.add(opr);
			operatorSet = Collections.unmodifiableSet(operatorSet);
			this.keywords = keywords;
			keywordSet = new HashSet<String>();
			for (String opr: keywords)
				keywordSet.add(opr);
			keywordSet = Collections.unmodifiableSet(keywordSet);
			
			// creating the identifier scanner
			Pattern idPattern = getIdenPatternPattern();
			Parser idScanner = Scanners.isPattern(idPattern, "identifier");
			
			words = Terms.getCaseSensitiveInstance(idScanner, operators, keywords);
			lexer = words.getLexer();
			
		} else
			throw new EngineError("Cannot re-initialize ParserTools.");
	}
	
	public Parser<Tok[]> getLexer() {
		return Lexers.lexeme(Parsers.one(), lexer);
	}
	
	/**
	 * Returns the singleton {@link StringTokenizer}.
	 */
	public StringTokenizer getStringTokenizer() {
		if (stringTokenizer == null)
			stringTokenizer = new StringTokenizer();
		return stringTokenizer;
	}
	
	/**
	 * Returns a parser that parses the character string <code>str</code>
	 */
	public Parser<Node> getOprParser(String str) {
		if (words == null)
			throw new EngineError("ParserTools.getOprParser(String) is called before the ParserTools object is initialized.");
		
		if (oprParsers == null)  
			oprParsers = new HashMap<String, Parser<Node>>();
		
		Parser<Node> parser = oprParsers.get(str);
		
		if (parser == null) {
			
			Parser<Tok> tokParser = null;
			try {
				tokParser = words.getParser(str); 
			} catch (IllegalArgumentException e) {
				throw new EngineError("Operator '" + str + "' is not registered by any plug-in.");
			}
			
			parser = tokParser.map(new LiteralMap("Kernel", Node.OPERATOR_NODE));
			oprParsers.put(str, parser);
		}
		
		return parser;
	}
	/* Change Series: Changing The Lexing Mechanism
	public Parser<Node> getOprParser(String str) {
		if (oprParsers == null)  
			oprParsers = new HashMap<String, Parser<Node>>();
		
		Parser<Node> parser = oprParsers.get(str);
		
		if (parser == null) {
			Pattern pattern = Patterns.isString(str);
			Parser scanner = Scanners.isPattern(pattern, "'" + str + "'");
			
			Parser<Tok> tokParser = Lexers.lexer("Operator-" + str, 
					scanner, 
					getStringTokenizer(), 
					"lexer error: expecting '" + str + "'");
			
			parser = tokParser.map(new LiteralMap("Kernel", Node.OPERATOR_NODE));
			oprParsers.put(str, parser);
		}
		
		return parser;
	}
	*/
	
	/**
	 * Returns the set of all the operators defined so far.
	 */
	public Set<String> getOperators() {
		if (operatorSet != null) {
			return operatorSet;
		}
		else
			return Collections.emptySet();
	}
	/* Change Series: Changing The Lexing Mechanism
	public Set<String> getOperators() {
		if (oprParsers != null)
			return oprParsers.keySet();
		else
			return Collections.emptySet();
	}
	*/
	
	/**
	 * Provides a keyword parser that would parse a keyword into a 
	 * properly created {@link Node} object.
	 * 
	 * @param keyword the keyword
	 * @param pluginName plugin name
	 */
	public Parser<Node> getKeywordParser(String keyword, String pluginName) {
		if (words == null)
			throw new EngineError("ParserTools.getKeywordParser(...) is called before the ParserTools object is initialized.");
		
		if (kwParsers == null)  
			kwParsers = new HashMap<String, Parser<Node>>();
		
		Parser<Node> parser = kwParsers.get(keyword);
		
		if (parser == null) {

			Parser<Tok> tokParser = null; 
			try {
//				tokParser = words.getParser(keyword);
				tokParser = Parsers.token(new FromToken<Tok>() {

					public Tok fromToken(Tok tok) {
						return tok;
					}});
			} catch (IllegalArgumentException e) {
				throw new EngineError("Keyword '" + keyword + "' is not registered by any plug-in.");
			}

			parser = Parsers.parseTokens(Lexers.lexeme(Scanners.haskellDelimiter(), lexer), 
					tokParser.map(new LiteralMap(pluginName, Node.KEYWORD_NODE)), "testKeyword");
//			parser = tokParser.map(new LiteralMap(pluginName, Node.KEYWORD_NODE));
//			parser = Parsers.map(keyword + "_parser", tokParser, new LiteralMap(pluginName, Node.KEYWORD_NODE));
			kwParsers.put(keyword, parser);
		}
		
		return parser;
	}
	/* Change Series: Changing The Lexing Mechanism 
	public Parser<Node> getKeywordParser(String keyword, String pluginName) {
		if (kwParsers == null)  
			kwParsers = new HashMap<String, Parser<Node>>();
		
		Parser<Node> parser = kwParsers.get(keyword);
		
		if (parser == null) {

			Pattern pattern = Patterns.isString(keyword);
			Parser scanner = Scanners.isPattern(pattern, "'" + keyword + "'");
			
			Parser<Tok> tokParser = Lexers.lexer("Keyword-" + keyword, 
					scanner, 
					getStringTokenizer(), 
					"lexer error: expecting '" + keyword + "'");
			
			parser = tokParser.map(new LiteralMap(pluginName, Node.KEYWORD_NODE));
			kwParsers.put(keyword, parser);
		}
		
		return parser;
	}
	/**/

	/**
	 * Returns the set of all the keywords defined so far.
	 */
	public Set<String> getKeywords() {
		if (keywordSet != null)
			return keywordSet;
		else
			return Collections.emptySet();
	}
	/* Change Series: Changing The Lexing Mechanism
	public Set<String> getKeywords() {
		if (kwParsers != null)
			return kwParsers.keySet();
		else
			return Collections.emptySet();
	}
	*/
	
	/**
	 * Returns a whitespace parser singleton.
	 */
	public  Parser<Node> getWhitespaceParser() {
		if (whitespaceParser == null) {
			Parser<_> whitespaceScanner = Scanners.isWhitespaces();
			Parser<Tok> wsTokParser = Lexers.lexer("Whitespace", 
					whitespaceScanner, 
					getStringTokenizer(), 
					"lexer error: whitespace");
			whitespaceParser = wsTokParser.map(new WhitespaceMap());
		}
		return whitespaceParser;
	}

	/**
	 * Returns a delimiter parser singleton. Such a parser includes 
	 * whitespaces and comments.
	 * 
	 */
	public  Parser<Node> getDelimiterParser() {
		if (delimiterParser == null) {
			Parser<_> lineCommentScanner = Scanners.javaLineComment();
			Parser<Tok> lcTokParser = Lexers.lexer("Java Line Comment", 
					lineCommentScanner, 
					getStringTokenizer(), 
					"lexer error: line comment");
			Parser<Node> lcParser = lcTokParser.map(new CommentMap());
			
			Parser<_> blockCommentScanner = Scanners.isBlockComment("/*", "*/");
			Parser<Tok> bcTokParser = Lexers.lexer("Block Comment", 
					blockCommentScanner, 
					getStringTokenizer(), 
					"lexer error: block comment");
			Parser<Node> bcParser = bcTokParser.map(new CommentMap());
			
			Parser<_> whitespaceScanner = Scanners.isWhitespaces();
			Parser<Tok> wsTokParser = Lexers.lexer("Whitespace", 
					whitespaceScanner, 
					getStringTokenizer(), 
					"lexer error: whitespace");
			Parser<Node> wsParser = wsTokParser.map("Whitespace", new WhitespaceMap());
			
			Parser<Object[]> optDelimParsers = Parsers.sum(lcParser, bcParser, wsParser).many(Object.class);
			optionalDelimiterParser = Parsers.map("delimiter", optDelimParsers, new DelimiterMap());

			Parser<Object[]> delimParsers = Parsers.sum(lcParser, bcParser, wsParser).many(Object.class, 1);
			delimiterParser = Parsers.map("delimiter", delimParsers, new DelimiterMap());
			
			Parser<_> spaceTabScanner = Scanners.isPattern(Patterns.among(new char[] {' ', '\t'}), "space");
			Parser<Tok> stTokParser = Lexers.lexer("Space/Tab", 
					spaceTabScanner, 
					getStringTokenizer(), 
					"lexer error: space/tab");
			Parser<Node> stParser = stTokParser.map("Space/Tabl", new WhitespaceMap());
			Parser<Node[]> stDelimParser = stParser.many(Node.class);
			spaceTabDelimParser = Parsers.map("space/tab", stDelimParser, new DelimiterMap());
			
			nonEOLDelimParser = delimiterParser.isReturn(new ObjectPredicate<Node>() {

				public boolean isObject(Node v) {
					return !v.getToken().contains("\n");
				}
				
			});

			eolDelimParser = delimiterParser.isReturn(new ObjectPredicate<Node>() {

				public boolean isObject(Node v) {
					return v.getToken().contains("\n");
				}
				
			});

		}
		return delimiterParser;
	}
	
	/**
	 * Returns an optional delimiter parser singleton. Such a parser includes 
	 * whitespaces and comments.
	 * 
	 */
	public  Parser<Node> getOptionalDelimiterParser() {
		if (delimiterParser == null) {
			getDelimiterParser();
		}
		return optionalDelimiterParser;
	}

	/**
	 * Returns a delimiter parser singleton that accept at least one EOL. Such a parser includes 
	 * whitespaces and comments.
	 * 
	 */
	public  Parser<Node> getEOLDelimiterParser() {
		if (delimiterParser == null) {
			getDelimiterParser();
		}
		return eolDelimParser;
	}

	/**
	 * Returns a delimiter parser singleton that does not accept EOL. Such a parser includes 
	 * whitespaces and comments.
	 * 
	 */
	public  Parser<Node> getNonEOLDelimiterParser() {
		if (delimiterParser == null) {
			getDelimiterParser();
		}
		return nonEOLDelimParser;
	}

	/**
	 * Returns a delimiter parser singleton that only accepts space and tab. 
	 * 
	 */
	public  Parser<Node> getSTDelimiterParser() {
		if (delimiterParser == null) {
			getDelimiterParser();
		}
		return spaceTabDelimParser;
	}

	/**
	 * Provides an identifier parser that would parse a CoreASM identifier into a 
	 * properly created {@link Node} object.
	 * 
	 */
	public Parser<Node> getIdentifierParser() {

		if (identifierParser == null) {
			Parser<Tok> tokParser = lexer;
			
			identifierParser = tokParser.map(new IdentifierMap());
		}
		
		return identifierParser;
	}
	/* Change Series: Changing The Lexing Mechanism
	public Parser<Node> getIdentifierParser() {

		if (identifierParser == null) {
			Pattern pattern = getIdenPatternPattern();
			//Pattern pattern = Patterns.isWord();
			Parser scanner = Scanners.isPattern(pattern, "an Identifier");
			
			Parser<Tok> tokParser = Lexers.lexer("Identifier", 
					scanner, 
					getStringTokenizer(), 
					"lexer error: expecting an identifier");
			
			identifierParser = tokParser.map(new IdentifierMap());
		}
		
		return identifierParser;
	}
	*/
	
	/**
	 * Returns an identifier pattern singleton. This pattern
	 * does not accept a keyword or an operator as an identifier.
	 * 
	 * @return
	 */
	public Pattern getIdenPatternPattern(){
		if (identifierPattern == null) {
			 identifierPattern = new Pattern() {
				public int match(final CharSequence src, final int len, final int from) {
			        if(from > len) return Pattern.MISMATCH;
					final java.util.regex.Pattern p = java.util.regex.Pattern.compile("[a-zA-Z_][0-9a-zA-Z_]*[']*");
			        final Matcher matcher = p.matcher(src.subSequence(from, len));
			        if (matcher.lookingAt()) {
			        	int end = matcher.end();
						String input = src.subSequence(from, from + end).toString();
						if (getKeywords().contains(input) || getOperators().contains(input))
							return Pattern.MISMATCH;
						else
							return end;
			        } else
			        	return Pattern.MISMATCH;
				}

				public String toString(){
					return "identifier";
				}
			};
		}
		return identifierPattern;
	}


	/**
	 * A special Map that maps comments in form of {@link Tok} to {@link Node}.
	 * @author Roozbeh Farahbod
	 *
	 */
	public static final class CommentMap extends ParseMap<Tok, Node> {

		public CommentMap() {
			super("Kernel");
		}

		public Node map(Tok v) {
			return new Node(
					pluginName,
					v.toString(),
					new ScannerInfo(v),
					Node.COMMENT_NODE
					);
		}
		
	}

	/**
	 * A special Map that maps whitespaces in form of {@link Tok} to {@link Node}.
	 * @author Roozbeh Farahbod
	 *
	 */
	public static final class WhitespaceMap extends ParseMap<Tok, Node> {

		public WhitespaceMap() {
			super("Kernel");
		}

		public Node map(Tok v) {
			return new Node(
					pluginName,
					v.toString(),
					new ScannerInfo(v),
					Node.WHITESPACE_NODE
					);
		}
		
	}

	/**
	 * A special Map that maps {@link Tok} to {@link Node}.
	 * This is used for all literals.
	 * 
	 * @author Roozbeh Farahbod
	 *
	 */
	public static final class LiteralMap extends ParseMap<Tok, Node> {

		/**
		 * Creates a new literal map.
		 * 
		 * @param pluginName name of the plugin creating this literal
		 * @param literalType type of the literal. See {@link Node}.
		 */
		public LiteralMap(String pluginName, String literalType) {
			super(pluginName);
		}

		public Node map(Tok v) {
			return new Node(
					pluginName,
					v.toString(),
					new ScannerInfo(v),
					Node.KEYWORD_NODE
					);
		}
		
	}

	/**
	 * A special Map that maps {@link Tok} to {@link ASTNode} as
	 * an identifier.
	 *  
	 * @author Roozbeh Farahbod
	 *
	 */
	public static final class IdentifierMap extends ParseMap<Tok, Node> {

		public IdentifierMap() {
			super("Kernel");
		}

		
		public Node map(Tok v) {
			if (v.getToken() instanceof TypedToken)
				System.out.println("!!!!!!!!!!!!!!!!  YES! : " + v.toString());
			else
				System.out.println("No!");
			return new ASTNode(
							pluginName, 
							ASTNode.ID_CLASS, 
							"ID", 
							v.toString(),
							new ScannerInfo(v),
							Node.GENERAL_ID_NODE
							);
		}
		
	}

	/**
	 * Converts a <code>Parser&lt;Object&gt;</code> to a 
	 * <code>Parser&lt;Object[]&gt;</code> one.
	 *  
	 * @param parser 
	 */
	public Parser<Object[]> toObjectArray(Parser<? extends Object> parser) {
		return Parsers.map("", parser, new jfun.parsec.Map<Object, Object[]>() {

			public Object[] map(Object v) {
				Object[] result = new Object[1];
				result[0] = v;
				return result;
			}});
	}
	
	/**
	 * Returns a parser that is a sequence of the given parsers. 
	 * The resulting parser will return an array of Objects.
	 * <p>
	 * P: P1 ... Pn
	 *  
	 * @param parsers parsers to be sequenced
	 */
	public Parser<Object[]> seq(Parser<? extends Object>...parsers) {
		return seq("parser", parsers);
	}
	
	/**
	 * Returns a parser that is a sequence of the given parsers. 
	 * The resulting parser will return an array of Objects.
	 * <p>
	 * P: P1 ... Pn
	 *
	 * @param name name of the new parser
	 * @param parsers parsers to be sequenced
	 */
	public Parser<Object[]> seq(String name, Parser<? extends Object>...parsers) {
		Parser<Object[]> seqParser = Parsers.mapn(name, parsers, new ParseMapN<Object[]>("") {

			public Object[] map(Object... vals) {
				Object[] nodes = new Object[vals.length];
				
				for (int i=0; i < vals.length; i++) 
					nodes[i] = vals[i];
				
				return nodes;
			}
			
		});
			
		return seqParser;
	}
	
	/**
	 * Returns a parser P that is:
	 * <p>
	 * P: ( parser delimiter )*
	 *
	 * @param parsers parsers to be repeated
	 */
	public Parser<Object[]> star(Parser<? extends Object> parser) {
		return star("parser", parser);
	}
	
	/**
	 * Returns a parser P that is:
	 * <p>
	 * P: ( parser delimiter )*
	 * 
	 * @param name name of the new parser
	 * @param parsers parsers to be repeated
	 */
	public Parser<Object[]> star(String name, Parser<? extends Object> parser) {
		Parser<Object[]> result = seq(name, parser, getOptionalDelimiterParser()).many(Object[].class).map(
				new Map<Object[][], Object[]>() {

					public Object[] map(Object[][] v) {
						ArrayList list = new ArrayList();
						for (Object[] arr: v) 
							for (Object obj: arr)
								list.add(obj);
						return list.toArray();
					}
				}
		);
		
		return result;
	}
	
	/**
	 * Returns a parser P that is:
	 * <p>
	 * P: ( parser delimiter )+
	 *
	 * @param parsers parsers to be repeated at least once
	 */
	public Parser<Object[]> plus(Parser<? extends Object> parser) {
		return plus("parser", parser);
	}
	
	/**
	 * Returns a parser P that is:
	 * <p>
	 * P: ( parser delimiter )+
	 * 
	 * @param name name of the new parser
	 * @param parsers parsers to be repeated at least once
	 */
	public Parser<Object[]> plus(String name, Parser<? extends Object> parser) {
		return plus(name, parser, getOptionalDelimiterParser());
	}
	
	/**
	 * Returns a parser P that is:
	 * <p>
	 * P: ( parser delimiter )+
	 * 
	 * @param parsers parsers to be repeated at least once
	 * @param delimiter the delimiter parser
	 */
	public Parser<Object[]> plus(Parser<? extends Object> parser, Parser<Node> delimiter) {
		return plus("parser", parser, delimiter);
	}
	
	/**
	 * Returns a parser P that is:
	 * <p>
	 * P: ( parser delimiter )+
	 * 
	 * @param name name of the new parser
	 * @param parsers parsers to be repeated at least once
	 * @param delimiter the delimiter parser
	 */
	public Parser<Object[]> plus(String name, Parser<? extends Object> parser, Parser<Node> delimiter) {
		Parser<Object[]> result = seq(name, parser, delimiter).many1(Object[].class).map(
				new Map<Object[][], Object[]>() {

					public Object[] map(Object[][] v) {
						ArrayList list = new ArrayList();
						for (Object[] arr: v) 
							for (Object obj: arr)
								list.add(obj);
						return list.toArray();
					}
				}
		);
		
		return result;
	}
	
	/**
	 * Returns a parser P that is:
	 * <p>
	 * P: parser delimiter (',' delimiter parser delimiter)*
     * 
	 * @param parsers parsers to be repeated at least once
	 */
	public Parser<Object[]> csplus(Parser<? extends Object> parser) {
		return csplus("parser", parser);
	}
	
	/**
	 * Returns a parser P that is:
	 * <p>
	 * P: parser delimiter (commaParser delimiter parser delimiter)*
     * 
     * @param commaParser the parser that parses the comma or any other symbol 
	 * @param parsers parsers to be repeated at least once
	 */
	public Parser<Object[]> csplus(Parser<? extends Object> commaParser, Parser<? extends Object> parser) {
		return csplus("parser", commaParser, parser);
	}
	
	/**
	 * Returns a parser P that is:
	 * <p>
	 * P: parser delimiter (',' delimiter parser delimiter)*
	 * 
	 * @param name name of the new parser
	 * @param parsers parsers to be repeated at least once
	 */
	public Parser<Object[]> csplus(String name, Parser<? extends Object> parser) {
		return csplus(name, getOprParser(","), parser);
	}
	
	/**
	 * Returns a parser P that is:
	 * <p>
	 * P: parser delimiter (commaParser delimiter parser delimiter)*
	 * 
	 * @param name name of the new parser
	 * @param commaParser the parser that parses the comma or any other symbol
	 * @param parsers parsers to be repeated at least once
	 */
	public Parser<Object[]> csplus(String name, Parser<? extends Object> commaParser, Parser<? extends Object> parser) {
		Parser<Object[]> repeated = 
			star(
				seq(
					commaParser,
					getOptionalDelimiterParser(),
					parser,
					getOptionalDelimiterParser()
					)
				);
		
		Parser<Object[]> result = seq(name, 
				parser, 
				getOptionalDelimiterParser(),
				repeated
				);
		
		return result;
	}
	
	/**
	* Create a lazy evaluated parser.
	* When evaluated, it reads the parser object stored in an array indexed by pos.
	* @param placeholder the array that contains parser object.
	* @param pos the position (0-based) of the parser to lazily evaluate.
	* @return the lazy parser.
	*/
	public static <R> Parser<R> lazy(String name, final Parser<R>[] placeholder){
		return Parsers.lazy(name, new ParserEval<R>(){
			public Parser<R> eval() {
				return placeholder[0];
			}
		});
	}

	/**
	 * A tokenizer that returns a string ojbect as the token.
	 * 
	 * @author Roozbeh Farahbod
	 *
	 */
	public static final class StringTokenizer implements Tokenizer {

		/**
		 * Returns a {@link String} object as the token.
		 */
		public Object toToken(CharSequence cs, int from, int len) {
			return cs.subSequence(from, from + len).toString();
		}
		
	}
	
	/**
	 * A delimiter parse map.
	 *   
	 * @author Roozbeh Farahbod
	 *
	 */
	public static final class DelimiterMap implements Map<Object[], Node> {

		public Node map(Object[] v) {
			if (v.length == 0)
				return null;
			
			String token = "";
			Node node;
			ScannerInfo info = null;
			for (Object obj: v) {
				if (obj instanceof Node) {
					node = (Node)obj;
					if (node.getToken() != null)
						token = token + node.getToken();
					if (info == null)
						info = node.getScannerInfo();
				} else
					Logger.log(Logger.ERROR, Logger.parser, "One of the delimiters is not a Node object.");
			}
			return new Node(
					"Kernel",
					token,
					info,
					Node.DELIMITER_NODE);
		}

	}
}

